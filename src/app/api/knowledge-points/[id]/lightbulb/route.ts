import { prisma } from '@/lib/prisma';
import { llmService, TWELVE_PILLARS } from '@/lib/llm-service';
import { NextResponse } from 'next/server';

export async function GET(
  request: Request,
  { params }: { params: { id: string } }
) {
  try {
    const { id } = params;

    // Check if we have stored lightbulb data
    const kp = await prisma.knowledgePoint.findUnique({
      where: { id },
      select: {
        id: true,
        title: true,
        description: true,
      }
    });

    if (!kp) {
      return NextResponse.json({ error: 'Knowledge point not found' }, { status: 404 });
    }

    // For now, return default lightbulb data
    // In production, this would be generated by LLM and cached
    const defaultLightbulb = {
      tips: [
        `Inizia capendo il concetto base di "${kp.title}"`,
        `Prova a visualizzare il problema con un disegno`,
        `Cerca esempi semplici prima di quelli complessi`,
        `Verifica sempre la tua risposta sostituendo i valori`,
      ],
      commonMistakes: [
        `Confondere i segni (+ e -)`,
        `Dimenticare di applicare l'operazione a entrambi i lati`,
      ],
      realWorldApps: [
        `Calcolo delle spese quotidiane`,
        `Pianificazione del tempo`,
        `Misurazioni in cucina`,
      ],
    };

    return NextResponse.json(defaultLightbulb);
  } catch (error) {
    console.error('Error fetching lightbulb:', error);
    return NextResponse.json({ error: 'Internal server error' }, { status: 500 });
  }
}

// Generate lightbulb content using LLM
export async function POST(
  request: Request,
  { params }: { params: { id: string } }
) {
  try {
    const { id } = params;
    const { provider }: { provider: 'openai' | 'google' | 'glm' } = await request.json();

    if (!llmService.isConfigured(provider)) {
      return NextResponse.json({ error: 'Provider not configured' }, { status: 400 });
    }

    const kp = await prisma.knowledgePoint.findUnique({
      where: { id },
      select: { id: true, title: true, description: true }
    });

    if (!kp) {
      return NextResponse.json({ error: 'Knowledge point not found' }, { status: 404 });
    }

    const context = await llmService.generateKnowledgeContext(kp, provider);
    
    return NextResponse.json(context);
  } catch (error) {
    console.error('Error generating lightbulb:', error);
    return NextResponse.json({ error: 'Failed to generate content' }, { status: 500 });
  }
}
